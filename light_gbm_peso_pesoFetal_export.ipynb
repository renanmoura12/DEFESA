{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58a0fcfb-c29f-4139-9b8a-9a2228aa1c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape original: (571, 59)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PacienteId</th>\n",
       "      <th>Data</th>\n",
       "      <th>peso</th>\n",
       "      <th>imc</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>hipertensao</th>\n",
       "      <th>dataNascimento</th>\n",
       "      <th>dataProvavelParto</th>\n",
       "      <th>pesoPrimeiroTrimestre</th>\n",
       "      <th>origemRacial</th>\n",
       "      <th>...</th>\n",
       "      <th>ComprimentoNascimento</th>\n",
       "      <th>PerimetroCefalico</th>\n",
       "      <th>Apgar1Minuto</th>\n",
       "      <th>Apgar5Minutos</th>\n",
       "      <th>DiasHospital</th>\n",
       "      <th>Intercorrencias</th>\n",
       "      <th>TipoDiabetes</th>\n",
       "      <th>PrimeiroPesoGravidez</th>\n",
       "      <th>DataParto</th>\n",
       "      <th>DataPesoCartao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>25/11/2024</td>\n",
       "      <td>81</td>\n",
       "      <td>31.64</td>\n",
       "      <td>Sim</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>1989-06-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Diabetes Gestacional</td>\n",
       "      <td>72</td>\n",
       "      <td>45634.0</td>\n",
       "      <td>45629.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>11/06/2024</td>\n",
       "      <td>76</td>\n",
       "      <td>29.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pardo</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>07/05/2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>12/05/2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>168</td>\n",
       "      <td>11/12/2024</td>\n",
       "      <td>105</td>\n",
       "      <td>38.57</td>\n",
       "      <td>Sim</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>1990-07-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>46.0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Diabetes Gestacional</td>\n",
       "      <td>105</td>\n",
       "      <td>45641.0</td>\n",
       "      <td>45637.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PacienteId        Data peso    imc diabetes hipertensao dataNascimento  \\\n",
       "0          44  25/11/2024   81  31.64      Sim         N√£o     1989-06-16   \n",
       "1          44  11/06/2024   76  29.69      NaN         N√£o            NaN   \n",
       "2          44  07/05/2024  NaN    NaN      NaN         NaN            NaN   \n",
       "3          44  12/05/2023  NaN    NaN      NaN         NaN            NaN   \n",
       "4         168  11/12/2024  105  38.57      Sim         N√£o     1990-07-26   \n",
       "\n",
       "  dataProvavelParto  pesoPrimeiroTrimestre origemRacial  ...  \\\n",
       "0               NaN                    NaN          NaN  ...   \n",
       "1               NaN                    NaN        Pardo  ...   \n",
       "2        2024-12-19                    NaN          NaN  ...   \n",
       "3               NaN                    NaN          NaN  ...   \n",
       "4               NaN                    NaN          NaN  ...   \n",
       "\n",
       "  ComprimentoNascimento  PerimetroCefalico  Apgar1Minuto  Apgar5Minutos  \\\n",
       "0                  50.0               36.0           8.0            9.0   \n",
       "1                   NaN                NaN           NaN            NaN   \n",
       "2                   NaN                NaN           NaN            NaN   \n",
       "3                   NaN                NaN           NaN            NaN   \n",
       "4                  46.0               34.5           8.0            9.0   \n",
       "\n",
       "   DiasHospital  Intercorrencias          TipoDiabetes  PrimeiroPesoGravidez  \\\n",
       "0           2.0              NaN  Diabetes Gestacional                    72   \n",
       "1           NaN              NaN                   NaN                   NaN   \n",
       "2           NaN              NaN                   NaN                   NaN   \n",
       "3           NaN              NaN                   NaN                   NaN   \n",
       "4           1.0              NaN  Diabetes Gestacional                   105   \n",
       "\n",
       "  DataParto DataPesoCartao  \n",
       "0   45634.0        45629.0  \n",
       "1       NaN            NaN  \n",
       "2       NaN            NaN  \n",
       "3       NaN            NaN  \n",
       "4   45641.0        45637.0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, roc_curve,\n",
    "    precision_recall_curve, average_precision_score,\n",
    "    accuracy_score, confusion_matrix, classification_report\n",
    ")\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import shuffle\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "caminho = \"/Users/renanmoura/Documents/mestrado/PE-AI/data/dados.xlsx\"\n",
    "df = pd.read_excel(caminho)\n",
    "print(\"Shape original:\", df.shape)\n",
    "\n",
    "target_col = \"PreEclampsia\"\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5fa59f-4547-41f0-8b0f-bcd9c6a83ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392 gesta√ß√µes identificadas\n",
      "\n",
      "=== ESTAT√çSTICAS FINAIS ===\n",
      "idade: min=15.0, max=43.6, mean=32.0\n",
      "peso: min=35.0, max=119.1, mean=73.0\n",
      "imc: min=15.0, max=43.0, mean=28.3\n",
      "\n",
      "Shape final: (151, 63)\n",
      "Gesta√ß√µes √∫nicas: 146\n",
      "Sem NaNs nas features\n",
      "Target: {0: 127, 1: 24}\n"
     ]
    }
   ],
   "source": [
    "# MAPAS\n",
    "map_raca = {\"Branco\": 1, \"Pardo\": 2, \"Preto\": 3}\n",
    "map_boolean = {\n",
    "    \"Sim\": 1, \"YES\": 1, \"SIM\": 1, \"TRUE\": 1,\n",
    "    \"Nao\": 0, \"NAO\": 0, \"N√£o\": 0, \"N√ÉO\": 0, \"FALSE\": 0\n",
    "}\n",
    "map_hist_diabetes = {\n",
    "    \"N√£o\": 0, \"NAO\": 0, \"N√ÉO\": 0, \"Nao\": 0,\n",
    "    \"1¬∫ grau\": 3, \"1¬∞ GRAU\": 3, \"1 GRAU\": 3,\n",
    "    \"2¬∫ grau\": 2, \"2¬∞ GRAU\": 2, \"2 GRAU\": 2,\n",
    "    \"3¬∫ grau\": 1, \"3¬∞ GRAU\": 1, \"3 GRAU\": 1\n",
    "}\n",
    "\n",
    "# FEATURES \n",
    "input_features = [\n",
    "    \"idade\", \"imc\", \"diabetes\", \"hipertensao\",\n",
    "    \"origemRacial\", \"historicoFamiliarDiabetes\", \"TipoDiabetes\",\n",
    "    \"mediaIP\",\"perdasGestacionais\", \"peso\",\n",
    "    \"idadeGestacional\", \"idadeGestacionalCorrigida\", \"pesoFetal\",\n",
    "    \"percentilArteriaUterina\", \"percentilArtUmbilical\",\n",
    "    \"percentilPeso\",\"circunferenciaAbdominal\"\n",
    "]\n",
    "\n",
    "df_processed = df.copy()\n",
    "\n",
    "# IDADE POR PACIENTE\n",
    "\n",
    "if \"paciente_id\" in df_processed.columns:\n",
    "    paciente_ids = df_processed[\"paciente_id\"]\n",
    "else:\n",
    "    df_processed[\"paciente_id_temp\"] = df_processed[\n",
    "        [\"dataNascimento\",\"origemRacial\",\"imc\"]\n",
    "    ].astype(str).agg(\"_\".join, axis=1)\n",
    "    paciente_ids = df_processed[\"paciente_id_temp\"]\n",
    "\n",
    "df_processed[\"paciente_id_base\"] = paciente_ids\n",
    "\n",
    "data_referencia = pd.to_datetime(\"2025-12-02\")\n",
    "\n",
    "paciente_to_nasc = {}\n",
    "for pid in paciente_ids.unique():\n",
    "    nasc = pd.to_datetime(\n",
    "        df_processed.loc[paciente_ids == pid, \"dataNascimento\"],\n",
    "        errors=\"coerce\"\n",
    "    ).dropna()\n",
    "    paciente_to_nasc[pid] = nasc.mode().iloc[0] if len(nasc) else None\n",
    "\n",
    "def calc_idade(d):\n",
    "    if pd.isna(d):\n",
    "        return 28\n",
    "    return np.clip((data_referencia - d).days / 365.25, 15, 50)\n",
    "\n",
    "df_processed[\"idade\"] = df_processed[\"paciente_id_base\"].map(\n",
    "    lambda x: calc_idade(paciente_to_nasc.get(x))\n",
    ")\n",
    "\n",
    "# GESTA√á√ïES POR DATA\n",
    "\n",
    "if \"Data\" not in df_processed.columns:\n",
    "    raise ValueError(\"Coluna 'Data' (data da consulta) √© obrigat√≥ria\")\n",
    "\n",
    "df_processed[\"Data\"] = pd.to_datetime(\n",
    "    df_processed[\"Data\"], errors=\"coerce\", dayfirst=True\n",
    ")\n",
    "\n",
    "df_processed = df_processed.sort_values(\n",
    "    [\"paciente_id_base\",\"Data\"]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "MAX_GAP = 270   # dias (~9 meses)\n",
    "\n",
    "episodios = []\n",
    "\n",
    "for pid, grupo in df_processed.groupby(\"paciente_id_base\"):\n",
    "    datas = grupo[\"Data\"].values\n",
    "    ep = 1\n",
    "    \n",
    "    for i in range(len(grupo)):\n",
    "        if i == 0:\n",
    "            episodios.append(f\"{pid}\")\n",
    "            continue\n",
    "        \n",
    "        gap = (datas[i] - datas[i-1]).astype('timedelta64[D]').astype(int)\n",
    "        if gap > MAX_GAP:\n",
    "            ep += 1\n",
    "            \n",
    "        suf = \"\" if ep == 1 else chr(ord(\"A\") + ep - 2)\n",
    "        episodios.append(f\"{pid}{suf}\")\n",
    "\n",
    "df_processed[\"PacienteIdEpisodio\"] = episodios\n",
    "\n",
    "# CONVERS√ïES CATEG√ìRICAS\n",
    "\n",
    "if \"origemRacial\" in df_processed.columns:\n",
    "    df_processed[\"origemRacial\"] = (\n",
    "        df_processed[\"origemRacial\"]\n",
    "        .astype(str).str.strip()\n",
    "        .map(map_raca)\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "for col in [\"diabetes\",\"hipertensao\"]:\n",
    "    if col in df_processed.columns:\n",
    "        df_processed[col] = (\n",
    "            df_processed[col]\n",
    "            .astype(str).str.strip()\n",
    "            .map(map_boolean)\n",
    "            .astype(float)\n",
    "        )\n",
    "\n",
    "if \"historicoFamiliarDiabetes\" in df_processed.columns:\n",
    "    df_processed[\"historicoFamiliarDiabetes\"] = (\n",
    "        df_processed[\"historicoFamiliarDiabetes\"]\n",
    "        .astype(str).str.strip()\n",
    "        .replace(map_hist_diabetes)\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "if \"TipoDiabetes\" in df_processed.columns:\n",
    "    df_processed[\"TipoDiabetes\"] = (\n",
    "        df_processed[\"TipoDiabetes\"]\n",
    "        .astype(str).str.strip()\n",
    "        .replace({\n",
    "            \"Diabetes Gestacional\": 1,\n",
    "            \"Tipo 1\": 2,\n",
    "            \"Tipo 2\": 3\n",
    "        })\n",
    "    )\n",
    "    df_processed[\"TipoDiabetes\"] = pd.to_numeric(\n",
    "        df_processed[\"TipoDiabetes\"], errors=\"coerce\"\n",
    "    ).fillna(0)\n",
    "\n",
    "# DADOS OBST√âTRICOS\n",
    "\n",
    "if \"perdasGestacionais\" in df_processed.columns:\n",
    "    df_processed[\"perdasGestacionais\"] = (\n",
    "        pd.to_numeric(df_processed[\"perdasGestacionais\"], errors=\"coerce\")\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "if \"mediaIP\" in df_processed.columns:\n",
    "    df_processed[\"mediaIP\"] = np.where(\n",
    "        df_processed[\"mediaIP\"] >= 1.3,\n",
    "        df_processed[\"mediaIP\"] * 1.3,\n",
    "        df_processed[\"mediaIP\"]\n",
    "    )\n",
    "\n",
    "# peso = peso - pesoFetal\n",
    "\n",
    "peso_mae_kg = pd.to_numeric(df_processed[\"peso\"], errors=\"coerce\").fillna(0)\n",
    "peso_feto_g = pd.to_numeric(df_processed[\"pesoFetal\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "peso_feto_kg = peso_feto_g / 1000.0\n",
    "\n",
    "df_processed[\"peso\"] = (peso_mae_kg - peso_feto_kg).clip(lower=35)\n",
    "\n",
    "# GARANTIR NUM√âRICO + NAN\n",
    "\n",
    "for col in input_features:\n",
    "    if col not in df_processed.columns:\n",
    "        print(f\" Criando {col}=0\")\n",
    "        df_processed[col] = 0\n",
    "        \n",
    "    df_processed[col] = (\n",
    "        pd.to_numeric(df_processed[col], errors=\"coerce\")\n",
    "        .fillna(0)\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "# LIMITES CL√çNICOS\n",
    "\n",
    "def aplicar_limites_realistas(X, feature_names):\n",
    "    limites = {\n",
    "        \"idade\": (15, 50),\n",
    "        \"peso\": (35, 150),\n",
    "        \"imc\": (15, 50),\n",
    "        \"pesoFetal\": (0, 5000)\n",
    "    }\n",
    "    X = X.copy()\n",
    "    for f,(lo,hi) in limites.items():\n",
    "        if f in feature_names:\n",
    "            X[f] = X[f].clip(lo,hi)\n",
    "    return X\n",
    "\n",
    "df_processed[input_features] = aplicar_limites_realistas(\n",
    "    df_processed[input_features],\n",
    "    input_features\n",
    ")\n",
    "\n",
    "# ALVO\n",
    "\n",
    "alvo = (\n",
    "    df_processed[target_col]\n",
    "    .replace({True:1,False:0})\n",
    "    .astype(str).str.upper()\n",
    "    .replace({\"TRUE\":1,\"FALSE\":0})\n",
    ")\n",
    "\n",
    "alvo = pd.to_numeric(alvo, errors=\"coerce\")\n",
    "df_processed[target_col] = alvo.astype(\"Int64\")\n",
    "\n",
    "df_processed = df_processed[~df_processed[target_col].isna()]\n",
    "df_processed[target_col] = df_processed[target_col].astype(int)\n",
    "\n",
    "# ESTAT√çSTICAS FINAIS\n",
    "\n",
    "\n",
    "print(\"\\n=== ESTAT√çSTICAS FINAIS ===\")\n",
    "\n",
    "for c in [\"idade\",\"peso\",\"imc\"]:\n",
    "    s = df_processed[c]\n",
    "    print(f\"{c}: min={s.min():.1f}, max={s.max():.1f}, mean={s.mean():.1f}\")\n",
    "\n",
    "print(\n",
    "    f\"\\nShape final: {df_processed.shape}\"\n",
    "    f\"\\nGesta√ß√µes √∫nicas: {df_processed['PacienteIdEpisodio'].nunique()}\"\n",
    "    f\"\\nSem NaNs nas features\"\n",
    ")\n",
    "\n",
    "print(\"Target:\", df_processed[target_col].value_counts().to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45ceb183-bf93-43fc-9b94-2225e9a44c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino: (121, 17) | Teste: (30, 17)\n",
      "Pacientes treino: 121\n",
      "Pacientes teste: 30\n",
      "\n",
      "Distribui√ß√£o y_train:\n",
      "PreEclampsia\n",
      "0    100\n",
      "1     21\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribui√ß√£o y_test:\n",
      "PreEclampsia\n",
      "0    27\n",
      "1     3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Preparar dados\n",
    "X = df_processed[input_features].copy()\n",
    "y = df_processed[target_col].copy()\n",
    "groups = df_processed[\"PacienteIdEpisodio\"].values\n",
    "\n",
    "\n",
    "# Split por paciente\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.20, random_state=RANDOM_STATE)\n",
    "train_idx, test_idx = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "X_train = X.iloc[train_idx].reset_index(drop=True)\n",
    "X_test = X.iloc[test_idx].reset_index(drop=True)\n",
    "y_train = y.iloc[train_idx].reset_index(drop=True)\n",
    "y_test = y.iloc[test_idx].reset_index(drop=True)\n",
    "\n",
    "print(f\"Treino: {X_train.shape} | Teste: {X_test.shape}\")\n",
    "print(f\"Pacientes treino: {df_processed['PacienteId'].iloc[train_idx].nunique()}\")\n",
    "print(f\"Pacientes teste: {df_processed['PacienteId'].iloc[test_idx].nunique()}\")\n",
    "print(f\"\\nDistribui√ß√£o y_train:\\n{y_train.value_counts()}\")\n",
    "print(f\"\\nDistribui√ß√£o y_test:\\n{y_test.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a6c59be-ef75-4ce9-919c-8017b7268900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape ap√≥s SMOTE: (200, 17)\n",
      "Distribui√ß√£o p√≥s-SMOTE:\n",
      "PreEclampsia\n",
      "0    100\n",
      "1    100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=RANDOM_STATE)\n",
    "X_train_smote, y_train_smote = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Shape ap√≥s SMOTE: {X_train_smote.shape}\")\n",
    "print(f\"Distribui√ß√£o p√≥s-SMOTE:\\n{pd.Series(y_train_smote).value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6009f90-2d9a-4554-ac13-7fc931e8082e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape final ap√≥s augmentation: (280, 17)\n"
     ]
    }
   ],
   "source": [
    "X_np = X_train_smote.values\n",
    "y_np = y_train_smote.values.astype(float)\n",
    "\n",
    "cols_binarias = [\"diabetes\", \"hipertensao\"]\n",
    "\n",
    "cont_cols = [c for c in input_features if c not in cols_binarias]\n",
    "cont_idx = [input_features.index(c) for c in cont_cols]\n",
    "\n",
    "# Fun√ß√£o de augmenta√ß√£o com ru√≠do gaussiano\n",
    "def augment_gaussian_noise(X_np, y_np, factor=0.3, noise_std=0.02, random_state=None):\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    n_new = int(len(X_np) * factor)\n",
    "    if n_new == 0:\n",
    "        return X_np.copy(), y_np.copy()\n",
    "    idx = rng.randint(0, len(X_np), size=n_new)\n",
    "    X_new = X_np[idx].copy()\n",
    "\n",
    "    # ru√≠do s√≥ nas colunas cont√≠nuas\n",
    "    noise = rng.normal(0, noise_std, size=X_new[:, cont_idx].shape)\n",
    "    X_new[:, cont_idx] += noise\n",
    "\n",
    "    y_new = y_np[idx]\n",
    "    return X_new, y_new\n",
    "\n",
    "Xg, yg = augment_gaussian_noise(\n",
    "    X_np, y_np, factor=0.4, noise_std=0.02, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "X_aug = np.vstack([X_np, Xg])\n",
    "y_aug = np.concatenate([y_np, yg])\n",
    "X_final, y_final = shuffle(X_aug, y_aug, random_state=RANDOM_STATE)\n",
    "\n",
    "\n",
    "X_final_df = pd.DataFrame(X_final, columns=input_features)\n",
    "\n",
    "\n",
    "X_final_df = aplicar_limites_realistas(X_final_df, input_features)\n",
    "\n",
    "\n",
    "for col in cols_binarias:\n",
    "    if col in X_final_df.columns:\n",
    "        X_final_df[col] = X_final_df[col].clip(0, 1)\n",
    "\n",
    "X_final = X_final_df.values\n",
    "\n",
    "print(f\"Shape final ap√≥s augmentation: {X_final.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be514cb7-df3d-41bb-b660-e46007ffeae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino final: (202, 17)\n",
      "Valida√ß√£o: (36, 17)\n",
      "Teste final: (42, 17)\n"
     ]
    }
   ],
   "source": [
    "X_train_val, X_test_final, y_train_val, y_test_final = train_test_split(\n",
    "    X_final, y_final, test_size=0.15, stratify=np.round(y_final), random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.15, stratify=np.round(y_train_val), random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Treino final: {X_train_final.shape}\")\n",
    "print(f\"Valida√ß√£o: {X_val.shape}\")\n",
    "print(f\"Teste final: {X_test_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cc737cd-e05d-4fe7-a3bf-db769ff61346",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM treinado com sucesso!\n",
      "\n",
      "Top 10 features mais importantes:\n",
      "                    feature  importance\n",
      "9                      peso         287\n",
      "1                       imc         256\n",
      "0                     idade         164\n",
      "13  percentilArteriaUterina         111\n",
      "7                   mediaIP         102\n",
      "4              origemRacial          96\n",
      "14    percentilArtUmbilical          91\n",
      "15            percentilPeso          85\n",
      "3               hipertensao          83\n",
      "6              TipoDiabetes          79\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_final)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test_final)\n",
    "\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=input_features)\n",
    "X_val_scaled = pd.DataFrame(X_val_scaled, columns=input_features)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=input_features)\n",
    "\n",
    "# Suprimir warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    boosting_type='gbdt',\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.1,\n",
    "    num_leaves=31,\n",
    "    max_depth=6,\n",
    "    min_child_samples=20,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    verbosity=-1, \n",
    "    force_row_wise=True \n",
    ")\n",
    "\n",
    "\n",
    "lgb_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_final,\n",
    "    eval_set=[(X_val_scaled, y_val)],\n",
    "    eval_metric='binary_logloss',\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=100, verbose=False),  # verbose=False\n",
    "        lgb.log_evaluation(period=0, show_stdv=False)  # show_stdv=False\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"LightGBM treinado com sucesso!\")\n",
    "\n",
    "class ManualPipeline:\n",
    "    def __init__(self, scaler, model, feature_names):\n",
    "        self.scaler = scaler\n",
    "        self.model = model\n",
    "        self.feature_names = feature_names\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X_df = pd.DataFrame(X, columns=self.feature_names)\n",
    "        X_scaled = self.scaler.transform(X_df)\n",
    "        return self.model.predict_proba(X_scaled)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_df = pd.DataFrame(X, columns=self.feature_names)\n",
    "        X_scaled = self.scaler.transform(X_df)\n",
    "        return self.model.predict(X_scaled)\n",
    "\n",
    "trained_model = ManualPipeline(scaler, lgb_model, input_features)\n",
    "\n",
    "# import√¢ncia das features\n",
    "if hasattr(lgb_model, 'feature_importances_'):\n",
    "    feature_importance = lgb_model.feature_importances_\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': input_features,\n",
    "        'importance': feature_importance\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 features mais importantes:\")\n",
    "    print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1117997e-6757-4779-bbdd-91dca25c2db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes do augmentation:\n",
      "X_train_smote shape: (200, 17)\n",
      "Distribui√ß√£o y_train_smote: PreEclampsia\n",
      "0    100\n",
      "1    100\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Ap√≥s augmentation:\n",
      "X_final shape: (280, 17)\n",
      "Distribui√ß√£o y_final: 0.0    146\n",
      "1.0    134\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Antes do augmentation:\")\n",
    "print(f\"X_train_smote shape: {X_train_smote.shape}\")\n",
    "print(f\"Distribui√ß√£o y_train_smote: {pd.Series(y_train_smote).value_counts()}\")\n",
    "\n",
    "print(\"\\nAp√≥s augmentation:\")\n",
    "print(f\"X_final shape: {X_final.shape}\")\n",
    "print(f\"Distribui√ß√£o y_final: {pd.Series(y_final).value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3596252c-c7f2-4046-8811-5c3f7731603b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä M√©tricas calculadas:\n",
      "AUC: 0.9886\n",
      "Acur√°cia: 0.9286\n",
      "Precision: 0.9048\n",
      "Recall: 0.9500\n",
      "F1-Score: 0.9268\n",
      "Bundle salvo com sucesso!\n",
      "Features no modelo: 17\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "y_proba = lgb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "y_pred = (y_proba >= 0.5).astype(int)\n",
    "auc = roc_auc_score(y_test_final, y_proba)\n",
    "accuracy = accuracy_score(y_test_final, y_pred)\n",
    "precision = precision_score(y_test_final, y_pred)\n",
    "recall = recall_score(y_test_final, y_pred)\n",
    "f1 = f1_score(y_test_final, y_pred)\n",
    "\n",
    "print(f\"üìä M√©tricas calculadas:\")\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "print(f\"Acur√°cia: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "bundle_lgbm = {\n",
    "    \"model\": lgb_model,\n",
    "    \"scaler\": scaler,\n",
    "    \"input_features\": input_features,\n",
    "    \"target\": target_col,\n",
    "    \"map_raca\": map_raca,\n",
    "    \"map_boolean\": map_boolean,\n",
    "    \"map_hist_diabetes\": map_hist_diabetes,\n",
    "    \"performance\": {\n",
    "        \"auc\": auc,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    },\n",
    "    \"version\": \"2.0_otimizado_final\"\n",
    "}\n",
    "\n",
    "# Salvar\n",
    "bundle_path = \"/Users/renanmoura/Documents/mestrado/PE-AI/models/model_lgbm_bundle.pkl\"\n",
    "joblib.dump(bundle_lgbm, bundle_path)\n",
    "\n",
    "print(\"Bundle salvo com sucesso!\")\n",
    "print(f\"Features no modelo: {len(input_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "734e7c84-9da0-409f-835a-59ac32f46fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93        22\n",
      "           1       0.90      0.95      0.93        20\n",
      "\n",
      "    accuracy                           0.93        42\n",
      "   macro avg       0.93      0.93      0.93        42\n",
      "weighted avg       0.93      0.93      0.93        42\n",
      "\n",
      "\n",
      "Matriz de Confus√£o:\n",
      "[[20  2]\n",
      " [ 1 19]]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "y_proba = trained_model.predict_proba(X_test_final)[:, 1]\n",
    "y_pred = (y_proba >= 0.5).astype(int)\n",
    "y_test_int = np.round(y_test_final).astype(int)\n",
    "\n",
    "print(f\"\\nClassification Report:\\n{classification_report(y_test_int, y_pred)}\")\n",
    "print(f\"\\nMatriz de Confus√£o:\\n{confusion_matrix(y_test_int, y_pred)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
